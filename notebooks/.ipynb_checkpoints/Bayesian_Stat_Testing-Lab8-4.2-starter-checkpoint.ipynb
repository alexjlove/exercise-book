{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking the Hypothesis Testing 1 Step Forward with a Bayesian Twist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab will be divided into two sections. One we'll manually compute some of the Bayesian statistical testing procedures manually/step-wise using Python as a calculator, and the second half, we'll go ahead and use PyMC to go through the analysis and leverage the libraries to provide more automatic results for us. \n",
    "\n",
    "The first thing we'll do is load up the data set, which contains 3 columns, the number of clicks for a website on a given day, the number of sales conversions (actual sales) on a given day, and whether it was the weekend.\n",
    "\n",
    ">Note to instructor: This data is simulated, and I generated most of the click data using a Poisson process. Part of the \"extra\" challenge in this lab will be to see if the fast-learners can figure out which distribution to use outside of the normal distribution I've outlined here for them to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load the data\n",
    "CTR_dat = pd.read_csv('CSV/CTR_Sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clicks Conv</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clicks Conv  Clicks  Weekend\n",
       "0           11      19        0\n",
       "1           10      20        0\n",
       "2           11      17        0\n",
       "3           15      14        0\n",
       "4           11      18        0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CTR_dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our question will be simple: If we calculate the mean clicks for both the weekend and non-weekend days, can we determine which mean represents the \"true\" mean for the site? i.e. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we wanted to know which set of clicks (weekend or weekday) represented the \"true\" set of clicks on the website, how would we state it formally in a statistical test?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: $H_0$: Weekend Mean, $H_1$: Weekday Mean "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the Weekend Mean and the Weekday Mean of clicks and assign them to the variables Weekend_Mean and Weekday_Mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't really have any beliefs one way or the other. How would I state this in Bayesian terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have computed our priors, we need to move onto our likelihood function. Suppose I know that the true variance of clicks is 8. Further, we just got more 100 more days of observations all from mobile (as opposed to computer accessed) and the mean clicks is 25. Compute the Standard Error (SER) - Assuming the number of clicks is being drawn from a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the Z-scores and the associated Likelihoods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the total probability (remember from the first lecture):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's bring it all together, what is the posterior for the first hypothesis and the second hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've just completed a hands-on exercise computing a statistical test using Bayesian analysis. But how do we interpret it? Think about and discuss with your colleagues a while. Is this strong evidence for one hypothesis or another? What are the possible ways we could \"measure\" the strength of $H_0$ vis-a-vis $H_1$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credible Interval vs Confidence Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To review again in plain English, there is a clear difference between Credible and Confidence interval interpretations. \n",
    "\n",
    "**Confidence Intervals** : As the number of experimental trials increases X.X% ('X.X' being the desired confidence 'level') of the time, the confidence intervals will contain the \"true\" value of the parameter you are interested in (usually the mean). \n",
    "\n",
    "**Credible Intervals** : Given some data, there is a X.X% probability that the \"true\" value of your parameter is contained within your credible interval. \n",
    "\n",
    "As we discussed, the credible interval is much easier to explain to normal people, and does not require you to go into horse-shoe metaphors, or any other linguistic legerdemain. \n",
    "\n",
    "A subtle point that should be emphasized, much like other parts of Bayesian analysis, when one does the Bayesian \"inversion\" trick, often times what's being fixed in an analysis and what's being varied switches. No different here, observe that in the confidence interval, the parameter is fixed, but each iteration brings a new confidence interval (hence the horse-shoe metaphor). \n",
    "\n",
    "However, in the credible interval, it's the opposite, the interval is what's fixed, but the parameter value is what changes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a Bayesian basic stats test process with scikit-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before, we proceed with putting the above finger-calculations into code, let's do some quick visualizations comparing the data to a fitted normal distribution. In the following below, create 2 plots with a matplotlib graph that shows a histogram of that overplayed with distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot both distributions over each other. Does the graph visually confirm what you suspected based on the finger exercises above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Although scikit-learn isn't explicitly a Bayesian computing library, we are going to use standard statistical methods from it to compute the two posteriors above.\n",
    "\n",
    "First browse the following page (scikit-learn stats docs) http://docs.scipy.org/doc/scipy-0.14.0/reference/stats.html\n",
    "\n",
    "Now using the stats suite of methods, define the normal likelihood for both hypothesis 1 and 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normal_likelihood for hypothesis 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normal likelihood for hypothesis 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Great, proceed forward and define the total probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now bring it all together and define both posterior distributions based on the work above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Posterior 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Posterior 2\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
